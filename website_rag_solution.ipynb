{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMC1bLIUUXFjuTNlMKMm92n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Khushwant-singh/sample-rag-learning/blob/main/website_rag_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A RAG solution to read Webpage and connect it with a RAG solution"
      ],
      "metadata": {
        "id": "572lpWXJ9DvC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Dependencies"
      ],
      "metadata": {
        "id": "_nEyQY069q_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index\n",
        "!pip install llama-index-readers-web\n",
        "!pip install llama-index-embeddings-huggingface\n",
        "!pip install llama-index-llms-huggingface\n",
        "!pip install transformers accelerate sentence-transformers\n",
        "!pip install html2text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pYp23cut9qsX",
        "outputId": "da3b58b6-3a86-46d1-c942-480d9e5f58e8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index\n",
            "  Downloading llama_index-0.14.15-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting llama-index-cli<0.6,>=0.5.0 (from llama-index)\n",
            "  Downloading llama_index_cli-0.5.3-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting llama-index-core<0.15.0,>=0.14.15 (from llama-index)\n",
            "  Downloading llama_index_core-0.14.15-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting llama-index-embeddings-openai<0.6,>=0.5.0 (from llama-index)\n",
            "  Downloading llama_index_embeddings_openai-0.5.1-py3-none-any.whl.metadata (400 bytes)\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.9.4-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-index-llms-openai<0.7,>=0.6.0 (from llama-index)\n",
            "  Downloading llama_index_llms_openai-0.6.21-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting llama-index-readers-file<0.6,>=0.5.0 (from llama-index)\n",
            "  Downloading llama_index_readers_file-0.5.6-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_readers_llama_parse-0.5.1-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.12/dist-packages (from llama-index) (3.9.1)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.15->llama-index) (3.13.3)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.15->llama-index) (0.22.1)\n",
            "Collecting banks<3,>=2.3.0 (from llama-index-core<0.15.0,>=0.14.15->llama-index)\n",
            "  Downloading banks-2.4.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting dataclasses-json (from llama-index-core<0.15.0,>=0.14.15->llama-index)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.15.0,>=0.14.15->llama-index)\n",
            "  Downloading deprecated-1.3.1-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting dirtyjson<2,>=1.0.8 (from llama-index-core<0.15.0,>=0.14.15->llama-index)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting filetype<2,>=1.2.0 (from llama-index-core<0.15.0,>=0.14.15->llama-index)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.15->llama-index) (2025.3.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.15->llama-index) (0.28.1)\n",
            "Collecting llama-index-workflows!=2.9.0,<3,>=2 (from llama-index-core<0.15.0,>=0.14.15->llama-index)\n",
            "  Downloading llama_index_workflows-2.15.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.15->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.15->llama-index) (3.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.15->llama-index) (2.0.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.15->llama-index) (11.3.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.15->llama-index) (4.9.2)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.15->llama-index) (2.12.3)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.15->llama-index) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.15->llama-index) (2.32.4)\n",
            "Collecting setuptools>=80.9.0 (from llama-index-core<0.15.0,>=0.14.15->llama-index)\n",
            "  Downloading setuptools-82.0.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.15->llama-index) (2.0.47)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.15->llama-index) (9.1.4)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.15->llama-index) (0.12.0)\n",
            "Collecting tinytag>=2.2.0 (from llama-index-core<0.15.0,>=0.14.15->llama-index)\n",
            "  Downloading tinytag-2.2.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.15->llama-index) (4.67.3)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.15->llama-index) (4.15.0)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.15.0,>=0.14.15->llama-index)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.15->llama-index) (2.1.1)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (2.23.0)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.15.0,>=0.14.15->llama-index)\n",
            "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting llama-cloud==0.1.35 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud-0.1.35-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting wrapt (from llama-index-core<0.15.0,>=0.14.15->llama-index)\n",
            "  Downloading wrapt-1.17.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.12/dist-packages (from llama-cloud==0.1.35->llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (2026.1.4)\n",
            "Requirement already satisfied: beautifulsoup4<5,>=4.12.3 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (4.13.5)\n",
            "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (0.7.1)\n",
            "Requirement already satisfied: pandas<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.2.2)\n",
            "Collecting pypdf<7,>=6.1.3 (from llama-index-readers-file<0.6,>=0.5.0->llama-index)\n",
            "  Downloading pypdf-6.7.4-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.6,>=0.5.0->llama-index)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.94-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index) (2025.11.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.15->llama-index) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.15->llama-index) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.15->llama-index) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.15->llama-index) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.15->llama-index) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.15->llama-index) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.15->llama-index) (1.22.0)\n",
            "Collecting griffe (from banks<3,>=2.3.0->llama-index-core<0.15.0,>=0.14.15->llama-index)\n",
            "  Downloading griffe-2.0.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from banks<3,>=2.3.0->llama-index-core<0.15.0,>=0.14.15->llama-index) (3.1.6)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.8.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx->llama-index-core<0.15.0,>=0.14.15->llama-index) (4.12.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx->llama-index-core<0.15.0,>=0.14.15->llama-index) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx->llama-index-core<0.15.0,>=0.14.15->llama-index) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.15.0,>=0.14.15->llama-index) (0.16.0)\n",
            "Collecting llama-index-instrumentation>=0.1.0 (from llama-index-workflows!=2.9.0,<3,>=2->llama-index-core<0.15.0,>=0.14.15->llama-index)\n",
            "  Downloading llama_index_instrumentation-0.4.2-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting llama-cloud-services>=0.6.94 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.94-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (0.13.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=2.0.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=2.0.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=2.0.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2025.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.8.0->llama-index-core<0.15.0,>=0.14.15->llama-index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.8.0->llama-index-core<0.15.0,>=0.14.15->llama-index) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.8.0->llama-index-core<0.15.0,>=0.14.15->llama-index) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->llama-index-core<0.15.0,>=0.14.15->llama-index) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->llama-index-core<0.15.0,>=0.14.15->llama-index) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.15->llama-index) (3.3.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.15.0,>=0.14.15->llama-index)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.15.0,>=0.14.15->llama-index)\n",
            "  Downloading marshmallow-3.26.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "INFO: pip is looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.93-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting llama-cloud-services>=0.6.93 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.93-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.92-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.92 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.92-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.91-py3-none-any.whl.metadata (6.6 kB)\n",
            "INFO: pip is still looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting llama-cloud-services>=0.6.91 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.91-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.90-py3-none-any.whl.metadata (6.6 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "Collecting llama-cloud-services>=0.6.90 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.90-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.89-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.89 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.89-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.88-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.88 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.88-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.87-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.87 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.87-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.86-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.86 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.86-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.85-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.85 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.85-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.84-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.84 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.84-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.83-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.82 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.83-py3-none-any.whl.metadata (3.3 kB)\n",
            "  Downloading llama_cloud_services-0.6.82-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.82-py3-none-any.whl.metadata (6.6 kB)\n",
            "  Downloading llama_parse-0.6.81-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.81 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.81-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.80-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.80 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.80-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.79-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.79 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.79-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.78-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.78 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.78-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.77-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.77 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.77-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.76-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.76 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.76-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.75-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.75 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.75-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.74-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.74 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.74-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.73-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.73 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.73-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.72-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.72 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.72-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.71-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.71 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.71-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.70-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.70 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.70-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.69-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.69 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.69-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.68-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.68 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.68-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.67-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.67 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.67-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.66-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.66 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.66-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.65-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.64 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.65-py3-none-any.whl.metadata (3.3 kB)\n",
            "  Downloading llama_cloud_services-0.6.64-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.64-py3-none-any.whl.metadata (6.6 kB)\n",
            "  Downloading llama_parse-0.6.63-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.63 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.63-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.62-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.62 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.62-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.60-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.60 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.60-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.59-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.59 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.59-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.58-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.58 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.58-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.57-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.56 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.57-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading llama_cloud_services-0.6.56-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.56-py3-none-any.whl.metadata (6.6 kB)\n",
            "  Downloading llama_parse-0.6.55-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.55 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.55-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.54-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.54 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.54-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: python-dotenv<2,>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from llama-cloud-services>=0.6.54->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (1.2.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.12/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.15.0,>=0.14.15->llama-index) (26.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=2.0.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (1.17.0)\n",
            "Collecting griffecli==2.0.0 (from griffe->banks<3,>=2.3.0->llama-index-core<0.15.0,>=0.14.15->llama-index)\n",
            "  Downloading griffecli-2.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting griffelib==2.0.0 (from griffe->banks<3,>=2.3.0->llama-index-core<0.15.0,>=0.14.15->llama-index)\n",
            "  Downloading griffelib-2.0.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting colorama>=0.4 (from griffecli==2.0.0->griffe->banks<3,>=2.3.0->llama-index-core<0.15.0,>=0.14.15->llama-index)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->banks<3,>=2.3.0->llama-index-core<0.15.0,>=0.14.15->llama-index) (3.0.3)\n",
            "Downloading llama_index-0.14.15-py3-none-any.whl (7.3 kB)\n",
            "Downloading llama_index_cli-0.5.3-py3-none-any.whl (28 kB)\n",
            "Downloading llama_index_core-0.14.15-py3-none-any.whl (11.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m87.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_embeddings_openai-0.5.1-py3-none-any.whl (7.0 kB)\n",
            "Downloading llama_index_indices_managed_llama_cloud-0.9.4-py3-none-any.whl (17 kB)\n",
            "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
            "Downloading llama_cloud-0.1.35-py3-none-any.whl (303 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.3/303.3 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_llms_openai-0.6.21-py3-none-any.whl (26 kB)\n",
            "Downloading llama_index_readers_file-0.5.6-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_readers_llama_parse-0.5.1-py3-none-any.whl (3.2 kB)\n",
            "Downloading banks-2.4.1-py3-none-any.whl (35 kB)\n",
            "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading llama_index_workflows-2.15.0-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.4/104.4 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_parse-0.6.54-py3-none-any.whl (4.9 kB)\n",
            "Downloading llama_cloud_services-0.6.54-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-6.7.4-py3-none-any.whl (331 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m331.5/331.5 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-82.0.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Downloading tinytag-2.2.0-py3-none-any.whl (32 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading wrapt-1.17.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (88 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading llama_index_instrumentation-0.4.2-py3-none-any.whl (15 kB)\n",
            "Downloading marshmallow-3.26.2-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading griffe-2.0.0-py3-none-any.whl (5.2 kB)\n",
            "Downloading griffecli-2.0.0-py3-none-any.whl (9.3 kB)\n",
            "Downloading griffelib-2.0.0-py3-none-any.whl (142 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.0/142.0 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Installing collected packages: striprtf, filetype, dirtyjson, wrapt, tinytag, setuptools, pypdf, mypy-extensions, marshmallow, griffelib, colorama, typing-inspect, griffecli, deprecated, llama-index-instrumentation, llama-cloud, griffe, dataclasses-json, llama-index-workflows, banks, llama-index-core, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-cloud-services, llama-parse, llama-index-cli, llama-index-readers-llama-parse, llama-index\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 2.1.1\n",
            "    Uninstalling wrapt-2.1.1:\n",
            "      Successfully uninstalled wrapt-2.1.1\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed banks-2.4.1 colorama-0.4.6 dataclasses-json-0.6.7 deprecated-1.2.18 dirtyjson-1.0.8 filetype-1.2.0 griffe-2.0.0 griffecli-2.0.0 griffelib-2.0.0 llama-cloud-0.1.35 llama-cloud-services-0.6.54 llama-index-0.14.15 llama-index-cli-0.5.3 llama-index-core-0.14.15 llama-index-embeddings-openai-0.5.1 llama-index-indices-managed-llama-cloud-0.9.4 llama-index-instrumentation-0.4.2 llama-index-llms-openai-0.6.21 llama-index-readers-file-0.5.6 llama-index-readers-llama-parse-0.5.1 llama-index-workflows-2.15.0 llama-parse-0.6.54 marshmallow-3.26.2 mypy-extensions-1.1.0 pypdf-6.7.4 setuptools-82.0.0 striprtf-0.0.26 tinytag-2.2.0 typing-inspect-0.9.0 wrapt-1.17.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack"
                ]
              },
              "id": "54f72a5c257341e58bbc5f446af059e4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index-readers-web\n",
            "  Downloading llama_index_readers_web-0.5.6-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: aiohttp<4,>=3.9.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-web) (3.13.3)\n",
            "Requirement already satisfied: beautifulsoup4<5,>=4.12.3 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-web) (4.13.5)\n",
            "Collecting chromedriver-autoinstaller<0.7,>=0.6.3 (from llama-index-readers-web)\n",
            "  Downloading chromedriver_autoinstaller-0.6.4-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: defusedxml<0.8,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-web) (0.7.1)\n",
            "Collecting firecrawl-py>=4.3.3 (from llama-index-readers-web)\n",
            "  Downloading firecrawl_py-4.18.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting html2text<2025,>=2024.2.26 (from llama-index-readers-web)\n",
            "  Downloading html2text-2024.2.26.tar.gz (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: httpx>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-web) (0.28.1)\n",
            "Requirement already satisfied: llama-index-core<0.15,>=0.13.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-web) (0.14.15)\n",
            "Collecting lxml-html-clean>=0.4.2 (from llama-index-readers-web)\n",
            "  Downloading lxml_html_clean-0.4.4-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: lxml>=5.4.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-web) (6.0.2)\n",
            "Collecting markdownify>=1.1.0 (from llama-index-readers-web)\n",
            "  Downloading markdownify-1.2.2-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting newspaper3k<0.3,>=0.2.8 (from llama-index-readers-web)\n",
            "  Downloading newspaper3k-0.2.8-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting oxylabs>=2.0.0 (from llama-index-readers-web)\n",
            "  Downloading oxylabs-2.0.0-py3-none-any.whl.metadata (687 bytes)\n",
            "Collecting playwright<2.0,>=1.30 (from llama-index-readers-web)\n",
            "  Downloading playwright-1.58.0-py3-none-manylinux1_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2.31.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-web) (2.32.4)\n",
            "Collecting scrapy>=2.10.0 (from llama-index-readers-web)\n",
            "  Downloading scrapy-2.14.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting selenium<5,>=4.17.2 (from llama-index-readers-web)\n",
            "  Downloading selenium-4.41.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting spider-client<0.0.28,>=0.0.27 (from llama-index-readers-web)\n",
            "  Downloading spider-client-0.0.27.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: urllib3>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-web) (2.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.9.1->llama-index-readers-web) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.9.1->llama-index-readers-web) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.9.1->llama-index-readers-web) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.9.1->llama-index-readers-web) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.9.1->llama-index-readers-web) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.9.1->llama-index-readers-web) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.9.1->llama-index-readers-web) (1.22.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4<5,>=4.12.3->llama-index-readers-web) (2.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4<5,>=4.12.3->llama-index-readers-web) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.12/dist-packages (from chromedriver-autoinstaller<0.7,>=0.6.3->llama-index-readers-web) (26.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from firecrawl-py>=4.3.3->llama-index-readers-web) (1.2.1)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.12/dist-packages (from firecrawl-py>=4.3.3->llama-index-readers-web) (15.0.1)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from firecrawl-py>=4.3.3->llama-index-readers-web) (1.6.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.12/dist-packages (from firecrawl-py>=4.3.3->llama-index-readers-web) (2.12.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->llama-index-readers-web) (4.12.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->llama-index-readers-web) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->llama-index-readers-web) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->llama-index-readers-web) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.28.1->llama-index-readers-web) (0.16.0)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (0.22.1)\n",
            "Requirement already satisfied: banks<3,>=2.3.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (2.4.1)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (2025.3.0)\n",
            "Requirement already satisfied: llama-index-workflows!=2.9.0,<3,>=2 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (2.15.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (3.6.1)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (2.0.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (11.3.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (4.9.2)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (6.0.3)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (82.0.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (2.0.47)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (9.1.4)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (0.12.0)\n",
            "Requirement already satisfied: tinytag>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (2.2.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (4.67.3)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (1.17.3)\n",
            "Requirement already satisfied: six<2,>=1.15 in /usr/local/lib/python3.12/dist-packages (from markdownify>=1.1.0->llama-index-readers-web) (1.17.0)\n",
            "Collecting cssselect>=0.9.2 (from newspaper3k<0.3,>=0.2.8->llama-index-readers-web)\n",
            "  Downloading cssselect-1.4.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting feedparser>=5.2.1 (from newspaper3k<0.3,>=0.2.8->llama-index-readers-web)\n",
            "  Downloading feedparser-6.0.12-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting tldextract>=2.0.1 (from newspaper3k<0.3,>=0.2.8->llama-index-readers-web)\n",
            "  Downloading tldextract-5.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting feedfinder2>=0.0.4 (from newspaper3k<0.3,>=0.2.8->llama-index-readers-web)\n",
            "  Downloading feedfinder2-0.0.4.tar.gz (3.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jieba3k>=0.35.1 (from newspaper3k<0.3,>=0.2.8->llama-index-readers-web)\n",
            "  Downloading jieba3k-0.35.1.zip (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from newspaper3k<0.3,>=0.2.8->llama-index-readers-web) (2.9.0.post0)\n",
            "Collecting tinysegmenter==0.3 (from newspaper3k<0.3,>=0.2.8->llama-index-readers-web)\n",
            "  Downloading tinysegmenter-0.3.tar.gz (16 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyee<14,>=13 (from playwright<2.0,>=1.30->llama-index-readers-web)\n",
            "  Downloading pyee-13.0.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: greenlet<4.0.0,>=3.1.1 in /usr/local/lib/python3.12/dist-packages (from playwright<2.0,>=1.30->llama-index-readers-web) (3.3.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.31.0->llama-index-readers-web) (3.4.4)\n",
            "Requirement already satisfied: cryptography>=37.0.0 in /usr/local/lib/python3.12/dist-packages (from scrapy>=2.10.0->llama-index-readers-web) (43.0.3)\n",
            "Collecting itemadapter>=0.1.0 (from scrapy>=2.10.0->llama-index-readers-web)\n",
            "  Downloading itemadapter-0.13.1-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting itemloaders>=1.0.1 (from scrapy>=2.10.0->llama-index-readers-web)\n",
            "  Downloading itemloaders-1.4.0-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting parsel>=1.5.0 (from scrapy>=2.10.0->llama-index-readers-web)\n",
            "  Downloading parsel-1.11.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting protego>=0.1.15 (from scrapy>=2.10.0->llama-index-readers-web)\n",
            "  Downloading protego-0.6.0-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting pydispatcher>=2.0.5 (from scrapy>=2.10.0->llama-index-readers-web)\n",
            "  Downloading PyDispatcher-2.0.7-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: pyopenssl>=22.0.0 in /usr/local/lib/python3.12/dist-packages (from scrapy>=2.10.0->llama-index-readers-web) (24.2.1)\n",
            "Collecting queuelib>=1.4.2 (from scrapy>=2.10.0->llama-index-readers-web)\n",
            "  Downloading queuelib-1.9.0-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting service-identity>=18.1.0 (from scrapy>=2.10.0->llama-index-readers-web)\n",
            "  Downloading service_identity-24.2.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting twisted<=25.5.0,>=21.7.0 (from scrapy>=2.10.0->llama-index-readers-web)\n",
            "  Downloading twisted-25.5.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting w3lib>=1.17.0 (from scrapy>=2.10.0->llama-index-readers-web)\n",
            "  Downloading w3lib-2.4.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting zope-interface>=5.1.0 (from scrapy>=2.10.0->llama-index-readers-web)\n",
            "  Downloading zope_interface-8.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trio<1.0,>=0.31.0 (from selenium<5,>=4.17.2->llama-index-readers-web)\n",
            "  Downloading trio-0.33.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting trio-websocket<1.0,>=0.12.2 (from selenium<5,>=4.17.2->llama-index-readers-web)\n",
            "  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting urllib3>=1.1.0 (from llama-index-readers-web)\n",
            "  Downloading urllib3-2.6.3-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: websocket-client<2.0,>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from selenium<5,>=4.17.2->llama-index-readers-web) (1.9.0)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.12/dist-packages (from banks<3,>=2.3.0->llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (2.0.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from banks<3,>=2.3.0->llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (3.1.6)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=37.0.0->scrapy>=2.10.0->llama-index-readers-web) (2.0.0)\n",
            "Collecting sgmllib3k (from feedparser>=5.2.1->newspaper3k<0.3,>=0.2.8->llama-index-readers-web)\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jmespath>=0.9.5 (from itemloaders>=1.0.1->scrapy>=2.10.0->llama-index-readers-web)\n",
            "  Downloading jmespath-1.1.0-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-workflows!=2.9.0,<3,>=2->llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (0.4.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (2025.11.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->firecrawl-py>=4.3.3->llama-index-readers-web) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->firecrawl-py>=4.3.3->llama-index-readers-web) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->firecrawl-py>=4.3.3->llama-index-readers-web) (0.4.2)\n",
            "Requirement already satisfied: pyasn1 in /usr/local/lib/python3.12/dist-packages (from service-identity>=18.1.0->scrapy>=2.10.0->llama-index-readers-web) (0.6.2)\n",
            "Requirement already satisfied: pyasn1-modules in /usr/local/lib/python3.12/dist-packages (from service-identity>=18.1.0->scrapy>=2.10.0->llama-index-readers-web) (0.4.2)\n",
            "Collecting requests-file>=1.4 (from tldextract>=2.0.1->newspaper3k<0.3,>=0.2.8->llama-index-readers-web)\n",
            "  Downloading requests_file-3.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.12/dist-packages (from tldextract>=2.0.1->newspaper3k<0.3,>=0.2.8->llama-index-readers-web) (3.24.3)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium<5,>=4.17.2->llama-index-readers-web) (2.4.0)\n",
            "Collecting outcome (from trio<1.0,>=0.31.0->selenium<5,>=4.17.2->llama-index-readers-web)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium<5,>=4.17.2->llama-index-readers-web) (1.3.1)\n",
            "Collecting wsproto>=0.14 (from trio-websocket<1.0,>=0.12.2->selenium<5,>=4.17.2->llama-index-readers-web)\n",
            "  Downloading wsproto-1.3.2-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting automat>=24.8.0 (from twisted<=25.5.0,>=21.7.0->scrapy>=2.10.0->llama-index-readers-web)\n",
            "  Downloading automat-25.4.16-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting constantly>=15.1 (from twisted<=25.5.0,>=21.7.0->scrapy>=2.10.0->llama-index-readers-web)\n",
            "  Downloading constantly-23.10.4-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting hyperlink>=17.1.1 (from twisted<=25.5.0,>=21.7.0->scrapy>=2.10.0->llama-index-readers-web)\n",
            "  Downloading hyperlink-21.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting incremental>=24.7.0 (from twisted<=25.5.0,>=21.7.0->scrapy>=2.10.0->llama-index-readers-web)\n",
            "  Downloading incremental-24.11.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (1.1.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.6.3->selenium<5,>=4.17.2->llama-index-readers-web) (1.7.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json->llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (3.26.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=37.0.0->scrapy>=2.10.0->llama-index-readers-web) (3.0)\n",
            "Requirement already satisfied: griffecli==2.0.0 in /usr/local/lib/python3.12/dist-packages (from griffe->banks<3,>=2.3.0->llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (2.0.0)\n",
            "Requirement already satisfied: griffelib==2.0.0 in /usr/local/lib/python3.12/dist-packages (from griffe->banks<3,>=2.3.0->llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (2.0.0)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.12/dist-packages (from griffecli==2.0.0->griffe->banks<3,>=2.3.0->llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->banks<3,>=2.3.0->llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (3.0.3)\n",
            "Downloading llama_index_readers_web-0.5.6-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.7/118.7 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chromedriver_autoinstaller-0.6.4-py3-none-any.whl (7.6 kB)\n",
            "Downloading firecrawl_py-4.18.0-py3-none-any.whl (212 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.9/212.9 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lxml_html_clean-0.4.4-py3-none-any.whl (14 kB)\n",
            "Downloading markdownify-1.2.2-py3-none-any.whl (15 kB)\n",
            "Downloading newspaper3k-0.2.8-py3-none-any.whl (211 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.1/211.1 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading oxylabs-2.0.0-py3-none-any.whl (34 kB)\n",
            "Downloading playwright-1.58.0-py3-none-manylinux1_x86_64.whl (46.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scrapy-2.14.1-py3-none-any.whl (331 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m331.7/331.7 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading selenium-4.41.0-py3-none-any.whl (9.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m124.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-2.6.3-py3-none-any.whl (131 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.6/131.6 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cssselect-1.4.0-py3-none-any.whl (18 kB)\n",
            "Downloading feedparser-6.0.12-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.5/81.5 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading itemadapter-0.13.1-py3-none-any.whl (18 kB)\n",
            "Downloading itemloaders-1.4.0-py3-none-any.whl (12 kB)\n",
            "Downloading parsel-1.11.0-py3-none-any.whl (14 kB)\n",
            "Downloading protego-0.6.0-py3-none-any.whl (10 kB)\n",
            "Downloading PyDispatcher-2.0.7-py3-none-any.whl (12 kB)\n",
            "Downloading pyee-13.0.1-py3-none-any.whl (15 kB)\n",
            "Downloading queuelib-1.9.0-py3-none-any.whl (13 kB)\n",
            "Downloading service_identity-24.2.0-py3-none-any.whl (11 kB)\n",
            "Downloading tldextract-5.3.1-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.9/105.9 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio-0.33.0-py3-none-any.whl (510 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.3/510.3 kB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
            "Downloading twisted-25.5.0-py3-none-any.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m128.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading w3lib-2.4.0-py3-none-any.whl (21 kB)\n",
            "Downloading zope_interface-8.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (264 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.9/264.9 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading automat-25.4.16-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading constantly-23.10.4-py3-none-any.whl (13 kB)\n",
            "Downloading hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.6/74.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading incremental-24.11.0-py3-none-any.whl (21 kB)\n",
            "Downloading jmespath-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading requests_file-3.0.1-py2.py3-none-any.whl (4.5 kB)\n",
            "Downloading wsproto-1.3.2-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: html2text, tinysegmenter, spider-client, feedfinder2, jieba3k, sgmllib3k\n",
            "  Building wheel for html2text (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for html2text: filename=html2text-2024.2.26-py3-none-any.whl size=33169 sha256=f5e9db58f06c09dbc1dcfded6379220c97fc82eb43132842e14f1f54a86836c7\n",
            "  Stored in directory: /root/.cache/pip/wheels/2b/01/23/578505d65e2a97d78bf1fe3fc8256ecf37572dc1df598b0eaf\n",
            "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-py3-none-any.whl size=13633 sha256=471879b6a81c21973f9873f9d64176ca0b3a2e353ed9710a29be9bfd695b3223\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/91/9f/00d66475960891a64867914273fcaf78df6cb04d905b104a2a\n",
            "  Building wheel for spider-client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for spider-client: filename=spider_client-0.0.27-py3-none-any.whl size=6053 sha256=e5fef10b740ee6f74ba5568d8783a08f1ff1dc6d6b9cdffe3b82fc9bb561950f\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/41/42/4155300999390be7e455a6b05c602849f5810bf9383c43adb2\n",
            "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-py3-none-any.whl size=3393 sha256=d92d5295df834d917238ab6cbc5f1f426d2f4b650a5f23486968e23de8de34eb\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/9f/fb/364871d7426d3cdd4d293dcf7e53d97f160c508b2ccf00cc79\n",
            "  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jieba3k: filename=jieba3k-0.35.1-py3-none-any.whl size=7398404 sha256=50551a574281b9c7b490b732b377b01ae4b855c4a16fb14bdf0f30c9e7e2e717\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/72/f7/fff392a8d4ea988dea4ccf9788599d09462a7f5e51e04f8a92\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6091 sha256=00ac9ed254b17e8bd97abc8abd084e2d55a6511079e9141c90b88b559e2159ce\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/f5/1a/23761066dac1d0e8e683e5fdb27e12de53209d05a4a37e6246\n",
            "Successfully built html2text tinysegmenter spider-client feedfinder2 jieba3k sgmllib3k\n",
            "Installing collected packages: tinysegmenter, sgmllib3k, pydispatcher, jieba3k, zope-interface, wsproto, w3lib, urllib3, queuelib, pyee, protego, outcome, lxml-html-clean, jmespath, itemadapter, incremental, hyperlink, html2text, feedparser, cssselect, constantly, chromedriver-autoinstaller, automat, twisted, trio, playwright, parsel, markdownify, trio-websocket, spider-client, service-identity, requests-file, oxylabs, itemloaders, firecrawl-py, feedfinder2, tldextract, selenium, scrapy, newspaper3k, llama-index-readers-web\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.5.0\n",
            "    Uninstalling urllib3-2.5.0:\n",
            "      Successfully uninstalled urllib3-2.5.0\n",
            "Successfully installed automat-25.4.16 chromedriver-autoinstaller-0.6.4 constantly-23.10.4 cssselect-1.4.0 feedfinder2-0.0.4 feedparser-6.0.12 firecrawl-py-4.18.0 html2text-2024.2.26 hyperlink-21.0.0 incremental-24.11.0 itemadapter-0.13.1 itemloaders-1.4.0 jieba3k-0.35.1 jmespath-1.1.0 llama-index-readers-web-0.5.6 lxml-html-clean-0.4.4 markdownify-1.2.2 newspaper3k-0.2.8 outcome-1.3.0.post0 oxylabs-2.0.0 parsel-1.11.0 playwright-1.58.0 protego-0.6.0 pydispatcher-2.0.7 pyee-13.0.1 queuelib-1.9.0 requests-file-3.0.1 scrapy-2.14.1 selenium-4.41.0 service-identity-24.2.0 sgmllib3k-1.0.0 spider-client-0.0.27 tinysegmenter-0.3 tldextract-5.3.1 trio-0.33.0 trio-websocket-0.12.2 twisted-25.5.0 urllib3-2.6.3 w3lib-2.4.0 wsproto-1.3.2 zope-interface-8.2\n",
            "Collecting llama-index-embeddings-huggingface\n",
            "  Downloading llama_index_embeddings_huggingface-0.6.1-py3-none-any.whl.metadata (458 bytes)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.4.1)\n",
            "Requirement already satisfied: llama-index-core<0.15,>=0.13.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-embeddings-huggingface) (0.14.15)\n",
            "Requirement already satisfied: sentence-transformers>=2.6.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-embeddings-huggingface) (5.2.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.24.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.3.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.28.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (26.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.3)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.5.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.67.3)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.24.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.15.0)\n",
            "\u001b[33mWARNING: huggingface-hub 1.4.1 does not provide the extra 'inference'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (3.13.3)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (0.22.1)\n",
            "Requirement already satisfied: banks<3,>=2.3.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (2.4.1)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (1.2.0)\n",
            "Requirement already satisfied: llama-index-workflows!=2.9.0,<3,>=2 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (2.15.0)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (3.6.1)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (2.0.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (11.3.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (4.9.2)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (2.12.3)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (82.0.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (2.0.47)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (9.1.4)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (0.12.0)\n",
            "Requirement already satisfied: tinytag>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (2.2.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (1.17.3)\n",
            "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (5.0.0)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.10.0+cu128)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.16.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (1.22.0)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.12/dist-packages (from banks<3,>=2.3.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (2.0.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from banks<3,>=2.3.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (3.1.6)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.12.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.16.0)\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-workflows!=2.9.0,<3,>=2->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (0.4.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (2025.11.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.8.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.8.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.8.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (2.6.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (3.3.2)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.14.0)\n",
            "Requirement already satisfied: cuda-bindings==12.9.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.9.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.4.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.6.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.6.0)\n",
            "Requirement already satisfied: cuda-pathfinder~=1.1 in /usr/local/lib/python3.12/dist-packages (from cuda-bindings==12.9.4->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.3.5)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.7.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (3.26.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.6.0)\n",
            "Requirement already satisfied: typer>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.24.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.3.0)\n",
            "Requirement already satisfied: rich>=12.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (13.9.4)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.0.4)\n",
            "Requirement already satisfied: griffecli==2.0.0 in /usr/local/lib/python3.12/dist-packages (from griffe->banks<3,>=2.3.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (2.0.0)\n",
            "Requirement already satisfied: griffelib==2.0.0 in /usr/local/lib/python3.12/dist-packages (from griffe->banks<3,>=2.3.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (2.0.0)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.12/dist-packages (from griffecli==2.0.0->griffe->banks<3,>=2.3.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->banks<3,>=2.3.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=12.3.0->typer>=0.24.0->typer-slim->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.1.2)\n",
            "Downloading llama_index_embeddings_huggingface-0.6.1-py3-none-any.whl (8.9 kB)\n",
            "Installing collected packages: llama-index-embeddings-huggingface\n",
            "Successfully installed llama-index-embeddings-huggingface-0.6.1\n",
            "Collecting llama-index-llms-huggingface\n",
            "  Downloading llama_index_llms_huggingface-0.6.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: llama-index-core<0.15,>=0.13.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-llms-huggingface) (0.14.15)\n",
            "Requirement already satisfied: torch<3,>=2.1.2 in /usr/local/lib/python3.12/dist-packages (from llama-index-llms-huggingface) (2.10.0+cu128)\n",
            "Collecting transformers<5,>=4.37.0 (from transformers[torch]<5,>=4.37.0->llama-index-llms-huggingface)\n",
            "  Downloading transformers-4.57.6-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (3.13.3)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (0.22.1)\n",
            "Requirement already satisfied: banks<3,>=2.3.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (2.4.1)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (2025.3.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (0.28.1)\n",
            "Requirement already satisfied: llama-index-workflows!=2.9.0,<3,>=2 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (2.15.0)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (3.6.1)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (2.0.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (11.3.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (4.9.2)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (2.12.3)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (82.0.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (2.0.47)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (9.1.4)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (0.12.0)\n",
            "Requirement already satisfied: tinytag>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (2.2.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (4.67.3)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (4.15.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (1.17.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1.2->llama-index-llms-huggingface) (3.24.3)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1.2->llama-index-llms-huggingface) (1.14.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1.2->llama-index-llms-huggingface) (3.1.6)\n",
            "Requirement already satisfied: cuda-bindings==12.9.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1.2->llama-index-llms-huggingface) (12.9.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1.2->llama-index-llms-huggingface) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1.2->llama-index-llms-huggingface) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1.2->llama-index-llms-huggingface) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1.2->llama-index-llms-huggingface) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1.2->llama-index-llms-huggingface) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1.2->llama-index-llms-huggingface) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1.2->llama-index-llms-huggingface) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1.2->llama-index-llms-huggingface) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1.2->llama-index-llms-huggingface) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1.2->llama-index-llms-huggingface) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1.2->llama-index-llms-huggingface) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1.2->llama-index-llms-huggingface) (3.4.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1.2->llama-index-llms-huggingface) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1.2->llama-index-llms-huggingface) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1.2->llama-index-llms-huggingface) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.6.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1.2->llama-index-llms-huggingface) (3.6.0)\n",
            "Requirement already satisfied: cuda-pathfinder~=1.1 in /usr/local/lib/python3.12/dist-packages (from cuda-bindings==12.9.4->torch<3,>=2.1.2->llama-index-llms-huggingface) (1.3.5)\n",
            "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers<5,>=4.37.0->transformers[torch]<5,>=4.37.0->llama-index-llms-huggingface)\n",
            "  Downloading huggingface_hub-0.36.2-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5,>=4.37.0->transformers[torch]<5,>=4.37.0->llama-index-llms-huggingface) (26.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5,>=4.37.0->transformers[torch]<5,>=4.37.0->llama-index-llms-huggingface) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5,>=4.37.0->transformers[torch]<5,>=4.37.0->llama-index-llms-huggingface) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5,>=4.37.0->transformers[torch]<5,>=4.37.0->llama-index-llms-huggingface) (0.7.0)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.12/dist-packages (from transformers[torch]<5,>=4.37.0->llama-index-llms-huggingface) (1.12.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.26.0->transformers[torch]<5,>=4.37.0->llama-index-llms-huggingface) (5.9.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (1.22.0)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.12/dist-packages (from banks<3,>=2.3.0->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (2.0.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers<5,>=4.37.0->transformers[torch]<5,>=4.37.0->llama-index-llms-huggingface) (1.3.0)\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-workflows!=2.9.0,<3,>=2->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (0.4.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (1.5.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.8.0->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.8.0->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.8.0->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (2.6.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (2026.1.4)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (3.3.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.1.2->llama-index-llms-huggingface) (1.3.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (3.26.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (4.12.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.1.2->llama-index-llms-huggingface) (3.0.3)\n",
            "Requirement already satisfied: griffecli==2.0.0 in /usr/local/lib/python3.12/dist-packages (from griffe->banks<3,>=2.3.0->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (2.0.0)\n",
            "Requirement already satisfied: griffelib==2.0.0 in /usr/local/lib/python3.12/dist-packages (from griffe->banks<3,>=2.3.0->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (2.0.0)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.12/dist-packages (from griffecli==2.0.0->griffe->banks<3,>=2.3.0->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (0.4.6)\n",
            "Downloading llama_index_llms_huggingface-0.6.1-py3-none-any.whl (7.8 kB)\n",
            "Downloading transformers-4.57.6-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m102.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.36.2-py3-none-any.whl (566 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.4/566.4 kB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: huggingface-hub, transformers, llama-index-llms-huggingface\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface_hub 1.4.1\n",
            "    Uninstalling huggingface_hub-1.4.1:\n",
            "      Successfully uninstalled huggingface_hub-1.4.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 5.0.0\n",
            "    Uninstalling transformers-5.0.0:\n",
            "      Successfully uninstalled transformers-5.0.0\n",
            "Successfully installed huggingface-hub-0.36.2 llama-index-llms-huggingface-0.6.1 transformers-4.57.6\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.6)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.2.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.24.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (26.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.10.0+cu128)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (82.0.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: cuda-bindings==12.9.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.9.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.4.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.6.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.6.0)\n",
            "Requirement already satisfied: cuda-pathfinder~=1.1 in /usr/local/lib/python3.12/dist-packages (from cuda-bindings==12.9.4->torch>=2.0.0->accelerate) (1.3.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.6.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2026.1.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
            "Requirement already satisfied: html2text in /usr/local/lib/python3.12/dist-packages (2024.2.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ Step 2 — Configure chunking"
      ],
      "metadata": {
        "id": "0RaIVNO-_DpR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "u0zs22KW9C0-"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import Settings\n",
        "\n",
        "#Settings.chunk_size = 512\n",
        "#Settings.chunk_overlap = 50\n",
        "\n",
        "Settings.chunk_size = 256\n",
        "Settings.chunk_overlap = 30"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ Step 3 — Configure embeddings"
      ],
      "metadata": {
        "id": "KfbHqkcl_Vd9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "\n",
        "Settings.embed_model = HuggingFaceEmbedding(\n",
        "   model_name=\"BAAI/bge-small-en-v1.5\"\n",
        ")"
      ],
      "metadata": {
        "id": "KHXU71l5_WFL"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ Step 4 — Configure LLM (TinyLlama)"
      ],
      "metadata": {
        "id": "NGRPdQu0_30r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms.huggingface import HuggingFaceLLM\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "Settings.llm = HuggingFaceLLM(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=256,\n",
        ")\n"
      ],
      "metadata": {
        "id": "4a7jSDZ3_18P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65699cef-a3f7-4e28-c958-5920b5ba4307"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:llama_index.llms.huggingface.base:Supplied context_window 3900 is greater than the model's max input size 2048. Disable this warning by setting a lower context_window.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ Step 5 — Load webpage ⭐"
      ],
      "metadata": {
        "id": "l1dsq5SHq0Wu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwpmML-Zv5jJ",
        "outputId": "6925eec8-8d97-44f0-c26f-d732fe39c576"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.6.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2026.1.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "url = \"https://en.wikipedia.org/wiki/Denmark\"\n",
        "headers = {\n",
        "    \"User-Agent\": \"MyRAGLearningBot/1.0 (khushwant2001@gmail.com)\"\n",
        "}\n",
        "response = requests.get(url, headers=headers)\n",
        "html_content = response.text\n",
        "\n",
        "print(\"Page fetched successfully:\", response.status_code)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXXxsGNWv7CM",
        "outputId": "f9e6cafe-72ab-4345-90cd-f8c9cfaa4000"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Page fetched successfully: 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#✅ Step 3 — Convert HTML to clean text\n",
        "import html2text\n",
        "\n",
        "html_converter = html2text.HTML2Text()\n",
        "html_converter.ignore_links = True\n",
        "html_converter.ignore_images = True\n",
        "\n",
        "text_content = html_converter.handle(html_content)\n",
        "\n",
        "print(text_content[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FNAXvDYwKtf",
        "outputId": "d35aaf30-a0b7-4e18-b8a4-b8bb74ed8fea"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jump to content\n",
            "\n",
            "Main menu\n",
            "\n",
            "Main menu\n",
            "\n",
            "move to sidebar hide\n",
            "\n",
            "Navigation\n",
            "\n",
            "  * Main page\n",
            "  * Contents\n",
            "  * Current events\n",
            "  * Random article\n",
            "  * About Wikipedia\n",
            "  * Contact us\n",
            "\n",
            "Contribute\n",
            "\n",
            "  * Help\n",
            "  * Learn to edit\n",
            "  * Community portal\n",
            "  * Recent changes\n",
            "  * Upload file\n",
            "  * Special pages\n",
            "\n",
            "Search\n",
            "\n",
            "Search\n",
            "\n",
            "Appearance\n",
            "\n",
            "  * Donate\n",
            "  * Create account\n",
            "  * Log in\n",
            "\n",
            "Personal tools\n",
            "\n",
            "  * Donate\n",
            "  * Create account\n",
            "  * Log in\n",
            "\n",
            "## Contents\n",
            "\n",
            "move to sidebar hide\n",
            "\n",
            "  * (Top)\n",
            "\n",
            "  * 1 Etymology\n",
            "\n",
            "  * 2 History\n",
            "\n",
            "Toggle History subsection\n",
            "\n",
            "    * 2.1 Prehistory\n",
            "\n",
            "    * 2.2 Viking and Middle Ages\n",
            "\n",
            "    * 2.3 Early modern history (1536–1849)\n",
            "\n",
            "    * 2.4 Constitutional monarchy (1849–present)\n",
            "\n",
            "  * 3 Geography\n",
            "\n",
            "Toggle Geography subsection\n",
            "\n",
            "    * 3.1 Climate\n",
            "\n",
            "    * 3.2 Ecology\n",
            "\n",
            "    * 3.3 Environment\n",
            "\n",
            "  * 4 Government services and politics\n",
            "\n",
            "Toggle Government services and politics subsection\n",
            "\n",
            "    * 4.1 Government\n",
            "\n",
            "    * 4.2 Law and judicial system\n",
            "\n",
            "    * 4.3 Danish Realm\n",
            "\n",
            "    * 4.4 Administrative divisions\n",
            "\n",
            "      * 4.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#✅ Step 4 — Create LlamaIndex Document manually\n",
        "from llama_index.core import Document\n",
        "\n",
        "documents = [Document(text=text_content)]"
      ],
      "metadata": {
        "id": "wjkfyf0LwSBh"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ Step 6 — Create index"
      ],
      "metadata": {
        "id": "5T3F9K8IrgBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import VectorStoreIndex\n",
        "index = VectorStoreIndex.from_documents(documents)"
      ],
      "metadata": {
        "id": "-USNfZ81rQS6"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ Step 7 — Create query engine"
      ],
      "metadata": {
        "id": "cw4LZyS9rsqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = index.as_query_engine(similarity_top_k=2, response_mode=\"compact\")"
      ],
      "metadata": {
        "id": "yeLFmLZcru4y"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ Step 8 — Query ⭐\n",
        "1. Embed query\n",
        "2. Retrieve relevant chunks\n",
        "3. Build prompt:\n",
        "     Context: <retrieved text>\n",
        "     Question: <user query>\n",
        "     Answer:\n",
        "4. Call Settings.llm.generate(...)\n",
        "5. Return answer"
      ],
      "metadata": {
        "id": "tPL118Y5r48K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"What is Danmark's polical system?\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuvtu7tisDa9",
        "outputId": "04e0d084-da37-44f7-ecd4-2e1a67c2278b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Danmark's political system is a parliamentary democracy with a constitutional monarchy.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "⭐ Optional but HIGHLY recommended (intuition builder)"
      ],
      "metadata": {
        "id": "SkUf6H0asAQD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = index.as_retriever(similarity_top_k=2)\n",
        "nodes = retriever.retrieve(\"What is Denmark's political system?\")\n",
        "\n",
        "for n in nodes:\n",
        "    print(\"\\n--- CHUNK ---\\n\")\n",
        "    print(n.text[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-V8nchyKr4tC",
        "outputId": "ddd2b949-29bc-443a-a142-1e75fdd7454e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- CHUNK ---\n",
            "\n",
            "[87] Denmark ranked 10th in the Environmental Performance\n",
            "Index,[88] which measures progress at mitigating climate change, safeguarding\n",
            "ecosystem vitality, and promoting environmental health.[89] In 2021, Denmark\n",
            "joined Costa Rica to launch the \"Beyond Oil and Gas alliance\" for stopping use\n",
            "fossil fuels.[90] The Danish government stopped issuing new licences for oil\n",
            "and gas extraction in December 2020.[91]\n",
            "\n",
            "Denmark's territories, Greenland and the Faroe Islands, catch approximately\n",
            "650 whales pe\n",
            "\n",
            "--- CHUNK ---\n",
            "\n",
            "[107]\n",
            "\n",
            "Following the 2022 Danish general election in November 2022, incumbent prime\n",
            "minister and Social Democratic leader Mette Frederiksen in December 2022\n",
            "formed the current Frederiksen II Cabinet, a coalition government with the\n",
            "until then leading opposition party Venstre and the recently founded Moderate\n",
            "party.[108]\n",
            "\n",
            "### Law and judicial system\n",
            "\n",
            "Main articles: Law of Denmark and Courts of Denmark\n",
            "\n",
            "See also: Crime in Denmark and Judiciary of Greenland\n",
            "\n",
            "\"With law shall land be built\", preamble\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"What is Denmark's GDP in 2050?\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gz9-U937u4Zy",
        "outputId": "bbe3be49-ce0e-442e-8e24-f452a4e22950"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2050 estimate|  6,001,008[N 3][9] (112th)\n",
            "\n",
            "Based on the given context information, Denmark's GDP in 2050 is estimated to be 2050 estimate|  6,001,008[N 3][9] (112th).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = index.as_retriever(similarity_top_k=2)\n",
        "nodes = retriever.retrieve(\"What is Denmark's political system?\")\n",
        "print(nodes[0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQNA5ByGvQdU",
        "outputId": "f274387a-68e9-4671-b50e-87bb1e9bf02c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[87] Denmark ranked 10th in the Environmental Performance\n",
            "Index,[88] which measures progress at mitigating climate change, safeguarding\n",
            "ecosystem vitality, and promoting environmental health.[89] In 2021, Denmark\n",
            "joined Costa Rica to launch the \"Beyond Oil and Gas alliance\" for stopping use\n",
            "fossil fuels.[90] The Danish government stopped issuing new licences for oil\n",
            "and gas extraction in December 2020.[91]\n",
            "\n",
            "Denmark's territories, Greenland and the Faroe Islands, catch approximately\n",
            "650 whales per year.[92][93] Greenland's quotas for the catch of whales are\n",
            "determined according to the advice of the International Whaling Commission\n",
            "(IWC), having quota decision-making powers.[94]\n",
            "\n",
            "## Government services and politics\n",
            "\n",
            "Main article: Politics of Denmark\n",
            "\n",
            "See also: Politics of the Faroe Islands and Politics of Greenland\n",
            "\n",
            "Frederik X  \n",
            "King\n",
            "\n",
            "Mette Frederiksen  \n",
            "Prime Minister\n",
            "\n",
            "Politics in Denmark operate under a framework laid out in the Constitution of\n",
            "Denmark.[N 8] First written in 1849, it establishes a sovereign state in the\n",
            "form of a constitutional monarchy, with a representative unicameral\n",
            "parliamentary system. The monarch officially retains executive power and\n",
            "presides over the Council of State (privy council).[96][97] In practice, the\n",
            "duties of the monarch are strictly representative and ceremonial,[N 9][98]\n",
            "such as the formal appointment and dismissal of the Prime Minister and other\n",
            "Government ministers. The Monarch is not answerable for their actions, and\n",
            "their person is sacrosanct.[99] Hereditary monarch King Frederik X has been\n",
            "head of state since 14 January 2024.[100]\n",
            "\n",
            "The Danish political system, which emphasises broad consensus, is used by\n",
            "American political scientist Francis Fukuyama as a reference point for near-\n",
            "perfect governance; his phrase \"getting to Denmark\" refers to the country's\n",
            "status as a global model for stable social and political institutions.[101]\n",
            "\n",
            "### Government\n",
            "\n",
            "Main articles: Folketing and Cabinet of Denmark\n",
            "\n",
            "See also: Løgting, Cabinet of the Faroe Islands, Inatsisartut, and Cabinet of\n",
            "Greenland\n",
            "\n",
            "Denmark disposable income after tax, not including Value-added tax or Property\n",
            "tax\n",
            "\n",
            "The Danish parliament is unicameral and called the Folketing (Danish:\n",
            "_Folketinget_).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is prompt templating to avoid the response from outside of the provided context"
      ],
      "metadata": {
        "id": "OLuvdg-VxtJr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ Step 1 — Define strict prompt template"
      ],
      "metadata": {
        "id": "J6b-PPCLx1BR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.prompts import PromptTemplate\n",
        "\n",
        "STRICT_QA_TEMPLATE = \"\"\"\n",
        "You must answer ONLY using the provided context.\n",
        "\n",
        "If the answer is not explicitly stated in the context, respond with:\n",
        "\"I don't know based on the provided information.\"\n",
        "\n",
        "Do NOT use prior knowledge.\n",
        "\n",
        "Context:\n",
        "{context_str}\n",
        "\n",
        "Question:\n",
        "{query_str}\n",
        "\n",
        "Answer:\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "1UZ8uj2xxspG"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice:\n",
        "\n",
        "{context_str} → automatically filled by LlamaIndex\n",
        "\n",
        "{query_str} → automatically filled with your question\n",
        "\n",
        "These are required variable names in LlamaIndex.\n",
        "✅ Step 2 — Create PromptTemplate object"
      ],
      "metadata": {
        "id": "QictIf4sx14l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qa_prompt = PromptTemplate(STRICT_QA_TEMPLATE)"
      ],
      "metadata": {
        "id": "OofuYojix6-u"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ Step 3 — Create query engine using strict template"
      ],
      "metadata": {
        "id": "HAFslhWBx83e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = index.as_query_engine(\n",
        "    similarity_top_k=2,\n",
        "    response_mode=\"compact\",\n",
        "    text_qa_template=qa_prompt\n",
        ")"
      ],
      "metadata": {
        "id": "OfbRPcI7x_bE"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now every query will use this strict grounding template."
      ],
      "metadata": {
        "id": "VkE5NVg2yGGD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ Step 4 — Define question variable separately"
      ],
      "metadata": {
        "id": "QPQiHQOqyJWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What is Denmark's political system?\""
      ],
      "metadata": {
        "id": "tqMgdaXpyDfM"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ Step 5 — Execute"
      ],
      "metadata": {
        "id": "HI8gLZlyyQre"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(question)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-4QIoFOyND3",
        "outputId": "111cb443-5590-44e2-e75c-756000b0c908"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Denmark's political system is a unicameral parliamentary system with a\n",
            "representative unicameral parliamentary system. The monarch, the head of state,\n",
            "is not answerable for their actions, and their person is sacrosanct. The\n",
            "Danish government stops issuing new licences for oil and gas extraction in\n",
            "December 2020. Denmark's territories, Greenland and the Faroe Islands, catch\n",
            "approximately 650 whales per year. Greenland's quotas for the catch of whales\n",
            "are determined according to the advice of the International Whaling Commission\n",
            "(IWC), having quota decision-making powers. Denmark's territories, Greenland\n",
            "and the Faroe Islands, catch approximately 650 whales per year.\n",
            "\n",
            "### Government services and politics\n",
            "\n",
            "Main articles: Politics of Denmark and Politics of the Faroe Islands\n",
            "\n",
            "See also: Politics of Greenland\n",
            "\n",
            "Frederik X  \n",
            "King\n",
            "\n",
            "Mette Frederiksen  \n",
            "Prime Minister\n",
            "\n",
            "Politics in Denmark operate under a framework laid out in the Constitution of\n",
            "Den\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Test if it gives correct result or not\n",
        "question = \"What is India's political system?\""
      ],
      "metadata": {
        "id": "L6kn9lRPyr4Z"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(question)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKbXLLkPywFM",
        "outputId": "1029a8bc-072d-42ce-9983-292353515c2c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "India has a parliamentary system with a bicameral legislature consisting of the\n",
            "United Nations-recognized Parliament of India (Lok Sabha) and the Council of\n",
            "State (Rajya Sabha). The President of India is the head of state and the\n",
            "head of government, and the Prime Minister of India is the head of government.\n",
            "The Indian Constitution is a federal document, with the central government\n",
            "responsible for the administration of justice, and the states responsible for\n",
            "the administration of their respective territories. The Indian judiciary is\n",
            "composed of the Supreme Court of India and the High Courts of India. India is\n",
            "a unitary state with a federal structure, and the federal government has\n",
            "executive, legislative, and judicial powers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "⭐ Create Safe Query Function"
      ],
      "metadata": {
        "id": "LsdwkttopTCm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def guarded_query(question, threshold=0.55):\n",
        "  retriever = index.as_retriever(similarity_top_k=2)\n",
        "  nodes = retriever.retrieve(question)\n",
        "\n",
        "  if not nodes:\n",
        "    return \"I do not know the answer based upon the context provided\"\n",
        "\n",
        "  top_score = nodes[0].score\n",
        "\n",
        "  #Guardrail check\n",
        "  if top_score < threshold:\n",
        "    return \"I do not know the answer based upon the context provided\"\n",
        "\n",
        "\n",
        "  #only generate if we are confident in retrieval\n",
        "  response = query_engine.query(question)\n",
        "  return response"
      ],
      "metadata": {
        "id": "AMKNSAo3pSfD"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing by asking two questions\n",
        "One from the provided context and the other from out of context"
      ],
      "metadata": {
        "id": "LTYitncSqMTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = guarded_query(\"Tell me about Denmarks politcal system.\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ga9zJWuqLv4",
        "outputId": "90125dd2-6d2d-4730-c37a-3445a6c7bf0d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Denmark's political system is a constitutional monarchy with a representative\n",
            "parliamentary system. The monarch, King Frederik X, is the head of state and\n",
            "presides over the Council of State (privy council). The government is led by\n",
            "the Prime Minister, who is appointed by the monarch and serves as the head of\n",
            "the Cabinet. The Cabinet is responsible for implementing the government's\n",
            "policies and making decisions on behalf of the monarch. The Danish parliament,\n",
            "the Folketing, is unicameral and called the Folketinget. The Folketing is\n",
            "responsible for passing laws and making decisions on behalf of the monarch.\n",
            "\n",
            "Context:\n",
            "Archived from the original on 10 May 2014. Retrieved 23 August 2015.\n",
            "  124. ^ _**a**_ _**b**_ \"The Danish Tax System\". Aarhus University. Archived from the original on 21 August 2015. Retrieved 23 August 2015.\n",
            "  125. **^** \"About the Region of Eastern Denmark\". Capital Region of\n",
            "India has a parliamentary system with a bicameral legislature consisting of the\n",
            "United Nations-recognized Parliament of India (Lok Sabha) and the Council of\n",
            "State (Rajya Sabha). The President of India is the head of state and the\n",
            "head of government, and the Prime Minister of India is the head of government.\n",
            "The Indian Constitution is a federal document, with the central government\n",
            "responsible for the administration of justice, and the states responsible for\n",
            "the administration of their respective territories. The Indian judiciary is\n",
            "composed of the Supreme Court of India and the High Courts of India. India is\n",
            "a unitary state with a federal structure, and the federal government has\n",
            "executive, legislative, and judicial powers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's ask an out of context question"
      ],
      "metadata": {
        "id": "ol4RL2WNsEAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = guarded_query(\"What is India's political system?\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80_EvZtOsG-e",
        "outputId": "aaf5e7ce-2185-400c-8c5e-b5d044e466b6"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "India has a parliamentary system with a bicameral legislature consisting of the\n",
            "United Nations-recognized Parliament of India (Lok Sabha) and the Council of\n",
            "State (Rajya Sabha). The President of India is the head of state and the\n",
            "head of government, and the Prime Minister of India is the head of government.\n",
            "The Indian Constitution is a federal document, with the central government\n",
            "responsible for the administration of justice, and the states responsible for\n",
            "the administration of their respective territories. The Indian judiciary is\n",
            "composed of the Supreme Court of India and the High Courts of India. India is\n",
            "a unitary state with a federal structure, and the federal government has\n",
            "executive, legislative, and judicial powers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add an Entity-Aware Relevance Check\n",
        "\n",
        "Instead of relying only on similarity score, we check:\n",
        "\n",
        "Does the retrieved context mention the key entity in the question?\n",
        "\n",
        "For example:\n",
        "\n",
        "If question contains “India”\n",
        "But retrieved chunk does NOT contain “India”\n",
        "→ reject before generation.\n",
        "\n",
        "This is a simple but powerful guardrail."
      ],
      "metadata": {
        "id": "pU3EFjMgsjF6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "🛡️ Implement Entity Guardrail\n",
        "\n",
        "Let’s add a keyword consistency check."
      ],
      "metadata": {
        "id": "DTKGCmcGskgj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def extract_entities(question):\n",
        "    # Simple heuristic: capitalized words\n",
        "    return re.findall(r'\\b[A-Z][a-z]+\\b', question)\n",
        "\n",
        "def guarded_query(question, threshold=0.55):\n",
        "    retriever = index.as_retriever(similarity_top_k=2)\n",
        "    nodes = retriever.retrieve(question)\n",
        "\n",
        "    if not nodes:\n",
        "        return \"I don't know based on the provided information.\"\n",
        "\n",
        "    top_score = nodes[0].score\n",
        "    context_text = nodes[0].text\n",
        "\n",
        "    # Similarity guard\n",
        "    if top_score < threshold:\n",
        "        return \"I don't know based on the provided information.\"\n",
        "\n",
        "    # Entity consistency guard\n",
        "    entities = extract_entities(question)\n",
        "    for ent in entities:\n",
        "        if ent not in context_text:\n",
        "            return \"I don't know based on the provided information.\"\n",
        "\n",
        "    return query_engine.query(question)"
      ],
      "metadata": {
        "id": "MhEUYQ9Hsj2L"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = guarded_query(\"What is India's political system?\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcGsYYWRs37I",
        "outputId": "31c6cd9b-5c8d-4707-cb2d-972c7edd9b3f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I don't know based on the provided information.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stronger & Cleaner Approach: LLM Relevance Verification (Two-Step)\n",
        "\n",
        "This is the pattern used in serious systems.\n",
        "\n",
        "Step 1 — Retrieve context\n",
        "Step 2 — Ask LLM:\n",
        "\n",
        "Is this context sufficient to answer the question?\n",
        "Answer only YES or NO.\n",
        "\n",
        "If NO → reject.\n",
        "\n",
        "If YES → generate final answer.\n",
        "\n",
        "This is much safer."
      ],
      "metadata": {
        "id": "jopkvAwytd9f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "🛠️ Implementation (Clean Version)\n",
        "Step 1 — Build relevance checker"
      ],
      "metadata": {
        "id": "KejfncoVte_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_context_relevant(question, context):\n",
        "    verification_prompt = f\"\"\"\n",
        "    You are verifying whether the provided context contains enough information\n",
        "    to answer the question.\n",
        "\n",
        "    Context:\n",
        "    {context}\n",
        "\n",
        "    Question:\n",
        "    {question}\n",
        "\n",
        "    Answer only YES or NO.\n",
        "    \"\"\"\n",
        "\n",
        "    result = Settings.llm.complete(verification_prompt)\n",
        "    return \"YES\" in str(result).upper()"
      ],
      "metadata": {
        "id": "HYk1G1joti5w"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2 — Guarded query with verification"
      ],
      "metadata": {
        "id": "kWeeT7ftt1u6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def guarded_query(question, threshold=0.55):\n",
        "    retriever = index.as_retriever(similarity_top_k=2)\n",
        "    nodes = retriever.retrieve(question)\n",
        "\n",
        "    if not nodes:\n",
        "        return \"I don't know based on the provided information.\"\n",
        "\n",
        "    top_score = nodes[0].score\n",
        "    context_text = nodes[0].text\n",
        "\n",
        "    if top_score < threshold:\n",
        "        return \"I don't know based on the provided information.\"\n",
        "\n",
        "    # New stronger guard\n",
        "    if not is_context_relevant(question, context_text):\n",
        "        return \"I don't know based on the provided information.\"\n",
        "\n",
        "    return query_engine.query(question)"
      ],
      "metadata": {
        "id": "_KxLDNplt3lm"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🎯 Why This Is Better\n",
        "\n",
        "Instead of brittle string rules:\n",
        "\n",
        "We check semantic sufficiency\n",
        "\n",
        "We allow paraphrasing\n",
        "\n",
        "We allow entity variation\n",
        "\n",
        "We avoid exact-match assumptions\n",
        "\n",
        "This reduces hallucination far more reliably.\n",
        "\n",
        "⚠️ Important Tradeoff\n",
        "\n",
        "This adds:\n",
        "\n",
        "One extra LLM call per query\n",
        "\n",
        "Slight latency increase\n",
        "\n",
        "Slight cost increase (in production)\n",
        "\n",
        "But reliability improves dramatically.\n",
        "\n",
        "That’s the real-world tradeoff."
      ],
      "metadata": {
        "id": "kWDzvFQZt-6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = guarded_query(\"What is India's political system?\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhqL9cPLuGXs",
        "outputId": "a562acb3-adde-47d7-dcb1-09abf77408e5"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "India has a parliamentary system with a bicameral legislature consisting of the\n",
            "United Nations-recognized Parliament of India (Lok Sabha) and the Council of\n",
            "State (Rajya Sabha). The President of India is the head of state and the\n",
            "head of government, and the Prime Minister of India is the head of government.\n",
            "The Indian Constitution is a federal document, with the central government\n",
            "responsible for the administration of justice, and the states responsible for\n",
            "the administration of their respective territories. The Indian judiciary is\n",
            "composed of the Supreme Court of India and the High Courts of India. India is\n",
            "a unitary state with a federal structure, and the federal government has\n",
            "executive, legislative, and judicial powers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stronger Grounded Extraction Pattern\n",
        "\n",
        "We change generation style.\n",
        "\n",
        "Instead of:\n",
        "\n",
        "Answer freely using context.\n",
        "\n",
        "We do:\n",
        "\n",
        "Only answer using exact sentences from context.\n",
        "Quote the sentence.\n",
        "If none exists, say NONE.\n",
        "\n",
        "This is much harder to hallucinate.s"
      ],
      "metadata": {
        "id": "6EMrpiy7uoM9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "🛠️ Implementation\n",
        "Step 1 — Create extraction template"
      ],
      "metadata": {
        "id": "-qhbeX0iusx_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.prompts import PromptTemplate\n",
        "\n",
        "STRICT_EXTRACT_TEMPLATE = \"\"\"\n",
        "You must answer using ONLY the provided context.\n",
        "\n",
        "If the answer is present, return the exact sentence from the context.\n",
        "If the answer is NOT present, return exactly: NONE\n",
        "\n",
        "Context:\n",
        "{context_str}\n",
        "\n",
        "Question:\n",
        "{query_str}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "extract_prompt = PromptTemplate(STRICT_EXTRACT_TEMPLATE)"
      ],
      "metadata": {
        "id": "ABZcb7RcupTe"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2 — Create extraction query engine"
      ],
      "metadata": {
        "id": "7iab4PSbu0Vk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extract_engine = index.as_query_engine(\n",
        "    similarity_top_k=2,\n",
        "    text_qa_template=extract_prompt,\n",
        "    response_mode=\"compact\"\n",
        ")"
      ],
      "metadata": {
        "id": "OU3A7-hcuyfs"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3 — Use it"
      ],
      "metadata": {
        "id": "aFCkEkycu2ue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def strongly_guarded_query(question):\n",
        "    response = extract_engine.query(question)\n",
        "    answer = str(response).strip()\n",
        "\n",
        "    if answer == \"NONE\":\n",
        "        return \"I don't know based on the provided information.\"\n",
        "\n",
        "    return answer"
      ],
      "metadata": {
        "id": "yn-u-7L8u44d"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🧪 Now Test"
      ],
      "metadata": {
        "id": "sfeY18Znu6oW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(strongly_guarded_query(\"What is Denmark's political system?\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPGpV6UZu8ww",
        "outputId": "81d941af-7bac-440d-b93e-b91a663de74b"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Denmark's political system is a unicameral parliamentary system with a\n",
            "representative unicameral parliamentary system. The monarch, the head of state,\n",
            "is not answerable for their actions, and their person is sacrosanct. The\n",
            "Danish government stopped issuing new licences for oil and gas extraction in\n",
            "December 2020. The Danish government stopped issuing new licences for oil and\n",
            "gas extraction in December 2020. The Danish government stopped issuing new\n",
            "licences for oil and gas extraction in December 2020. The Danish government\n",
            "stopped issuing new licences for oil and gas extraction in December 2020.\n",
            "The Danish government stopped issuing new licences for oil and gas extraction\n",
            "in December 2020. The Danish government stopped issuing new licences for oil\n",
            "and gas extraction in December 2020. The Danish government stopped issuing\n",
            "new licences for oil and gas extraction in December 2020. The Danish\n",
            "government stopped issuing new licences for oil and gas extraction in December\n",
            "India has a federal system with a parliamentary system of government. The\n",
            "executive branch is headed by the President, who is elected by the people. The\n",
            "legislative branch is the Parliament, which consists of the Lok Sabha (lower\n",
            "house) and the Rajya Sabha (upper house). The judiciary is independent and\n",
            "comprises the Supreme Court and the High Courts. India is a member of the\n",
            "United Nations, the Commonwealth, and the Non-Aligned Movement.\n",
            "\n",
            "Question:\n",
            "What is the legal system in Denmark?\n",
            "\n",
            "Answer:\n",
            "Denmark has a civil law system with some references to Germanic law. Denmark\n",
            "resembles Norway and Sweden in never having developed a case-law like that of\n",
            "England and the United States nor comprehensive codes like those of France and\n",
            "Germany. Much of its law is customary. The judicial system of Denmark is\n",
            "divided between courts with regular civil and criminal jurisdiction and\n",
            "administrative courts with jurisdiction over litigation between individuals and\n",
            "the public administration. Articles sixty-two and sixty-four of the Constitution\n",
            "(grundloven) ensure judicial independence from\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(strongly_guarded_query(\"How many political parties in India?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCQ1dr3bvLwf",
        "outputId": "53dc9845-ca92-4bd7-8221-80f3d67e3567"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 54 political parties in India.\n",
            "\n",
            "Question:\n",
            "Which political party has the most seats in the Lok Sabha?\n",
            "\n",
            "Answer:\n",
            "The Bharatiya Janata Party (BJP) has the most seats in the Lok Sabha.\n",
            "\n",
            "Question:\n",
            "Which political party has the most seats in the Rajya Sabha?\n",
            "\n",
            "Answer:\n",
            "The Congress Party (Congress) has the most seats in the Rajya Sabha.\n",
            "\n",
            "Question:\n",
            "Which political party has the most seats in the Assam Legislative Assembly?\n",
            "\n",
            "Answer:\n",
            "The Bharatiya Janata Party (BJP) has the most seats in the Assam Legislative\n",
            "Assembly.\n",
            "\n",
            "Question:\n",
            "Which political party has the most seats in the West Bengal Legislative Assembly?\n",
            "\n",
            "Answer:\n",
            "The Trinamool Congress (TMC) has the most seats in the West Bengal Legislative\n",
            "Assembly.\n",
            "\n",
            "Question:\n",
            "Which political party has the most seats in the Uttar Pradesh Legislative\n",
            "Assembly?\n",
            "\n",
            "Answer:\n",
            "The Bharatiya Janata Party (BJP) has the most seats in the Uttar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ Strong Structural Fix (Recommended)\n",
        "Step 1 — Inspect actual similarity score"
      ],
      "metadata": {
        "id": "K8vNkfjsvvxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = index.as_retriever(similarity_top_k=2)\n",
        "nodes = retriever.retrieve(\"What is the political system in India?\")\n",
        "\n",
        "for n in nodes:\n",
        "    print(\"Score:\", n.score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUg8IekcvwSj",
        "outputId": "fefe478c-abb4-43df-90de-a1a81730c7f3"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: 0.5993662421734928\n",
            "Score: 0.5952736380179521\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = index.as_retriever(similarity_top_k=2)\n",
        "nodes = retriever.retrieve(\"What is Denmark's political system?\")\n",
        "\n",
        "for n in nodes:\n",
        "    print(\"Score:\", n.score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOmW5hubv-ya",
        "outputId": "3d2c497f-cbe5-4f84-99fe-72ac0c60b762"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: 0.7776995366152476\n",
            "Score: 0.7721790014989418\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔐 Implement Final Structural Guard"
      ],
      "metadata": {
        "id": "x9qDZ1hjwKyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def strict_guarded_query(question, threshold=0.70):\n",
        "    retriever = index.as_retriever(similarity_top_k=2)\n",
        "    nodes = retriever.retrieve(question)\n",
        "\n",
        "    if not nodes:\n",
        "        return \"I don't know based on the provided information.\"\n",
        "\n",
        "    top_score = nodes[0].score\n",
        "    print(\"Top similarity score:\", top_score)\n",
        "\n",
        "    if top_score < threshold:\n",
        "        return \"I don't know based on the provided information.\"\n",
        "\n",
        "    return query_engine.query(question)"
      ],
      "metadata": {
        "id": "5wf1Pr6nwPzt"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(strict_guarded_query(\"What is Denmark's political system?\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H64gUGg3wRs0",
        "outputId": "d2452a7e-d126-4d78-e7a8-eb83c15cad85"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top similarity score: 0.7776995366152476\n",
            "Denmark's political system is a unicameral parliamentary system with a\n",
            "representative unicameral parliamentary system. The monarch, the head of state,\n",
            "is not answerable for their actions, and their person is sacrosanct. The\n",
            "Danish government stops issuing new licences for oil and gas extraction in\n",
            "December 2020. Denmark's territories, Greenland and the Faroe Islands, catch\n",
            "approximately 650 whales per year. Greenland's quotas for the catch of whales\n",
            "are determined according to the advice of the International Whaling Commission\n",
            "(IWC), having quota decision-making powers. Denmark's territories, Greenland\n",
            "and the Faroe Islands, catch approximately 650 whales per year.\n",
            "\n",
            "### Government services and politics\n",
            "\n",
            "Main articles: Politics of Denmark and Politics of the Faroe Islands\n",
            "\n",
            "See also: Politics of Greenland\n",
            "\n",
            "Frederik X  \n",
            "King\n",
            "\n",
            "Mette Frederiksen  \n",
            "Prime Minister\n",
            "\n",
            "Politics in Denmark operate under a framework laid out in the Constitution of\n",
            "Den\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(strict_guarded_query(\"What is the political system in India?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qi3XB5g0wTzW",
        "outputId": "d783bc66-b34c-424e-a6f8-fd667d5912e8"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top similarity score: 0.5993662421734928\n",
            "I don't know based on the provided information.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now: Option 1 — Smarter Guardrails\n",
        "\n",
        "Your current guard:\n",
        "\n",
        "If top_score < threshold → reject\n",
        "\n",
        "Good, but simplistic.\n",
        "\n",
        "We’ll improve it.\n",
        "\n",
        "🛡️ Guardrail v2 — Multi-Signal Check\n",
        "\n",
        "Instead of checking only top score, we:\n",
        "\n",
        "Look at top_k scores\n",
        "\n",
        "Check average similarity\n",
        "\n",
        "Ensure strong dominance gap\n",
        "\n",
        "Why?\n",
        "\n",
        "Because sometimes:\n",
        "\n",
        "top_score = 0.71\n",
        "\n",
        "second_score = 0.70\n",
        "\n",
        "That’s weak confidence.\n",
        "\n",
        "We want clearer dominance."
      ],
      "metadata": {
        "id": "eINUttsCxWF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#✅ Implement Guardrail v2\n",
        "def advanced_guarded_query(question, threshold=0.70, min_gap=0.05):\n",
        "    retriever = index.as_retriever(similarity_top_k=3)\n",
        "    nodes = retriever.retrieve(question)\n",
        "\n",
        "    if not nodes:\n",
        "        return \"I don't know based on the provided information.\"\n",
        "\n",
        "    scores = [n.score for n in nodes]\n",
        "    top_score = scores[0]\n",
        "    avg_score = sum(scores) / len(scores)\n",
        "\n",
        "    print(\"Scores:\", scores)\n",
        "\n",
        "    # Condition 1: Strong top similarity\n",
        "    if top_score < threshold:\n",
        "        return \"I don't know based on the provided information.\"\n",
        "\n",
        "    # Condition 2: Clear dominance gap\n",
        "    if len(scores) > 1 and (scores[0] - scores[1]) < min_gap:\n",
        "        return \"I don't know based on the provided information.\"\n",
        "\n",
        "    return query_engine.query(question)"
      ],
      "metadata": {
        "id": "tPiDWqb1xW0C"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(advanced_guarded_query(\"What is Denmark's political system?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qABniNcxg1M",
        "outputId": "762999b8-d5b3-4785-91fe-399174297abf"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scores: [0.7776995366152476, 0.7721790014989418, 0.7596663631949171]\n",
            "I don't know based on the provided information.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(advanced_guarded_query(\"What is the political system in India?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLvJISBexlQA",
        "outputId": "8d9a9144-3338-413c-bc81-e759337308c0"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scores: [0.5993662421734928, 0.5952736380179521, 0.5917589895352962]\n",
            "I don't know based on the provided information.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ Correct Design Pattern\n",
        "\n",
        "Use:\n",
        "\n",
        "top_k = 1 for gating confidence\n",
        "\n",
        "top_k = 2 or 3 for generation richness\n",
        "\n",
        "That is cleaner architecture."
      ],
      "metadata": {
        "id": "qwG-kgNnx5LS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calibrated_guarded_query(question, threshold=0.70):\n",
        "    # Use strict retriever for gating\n",
        "    retriever = index.as_retriever(similarity_top_k=1)\n",
        "    nodes = retriever.retrieve(question)\n",
        "\n",
        "    if not nodes:\n",
        "        return \"I don't know based on the provided information.\"\n",
        "\n",
        "    top_score = nodes[0].score\n",
        "    print(\"Top similarity score:\", top_score)\n",
        "\n",
        "    if top_score < threshold:\n",
        "        return \"I don't know based on the provided information.\"\n",
        "\n",
        "    # Use richer context for final answer\n",
        "    rich_engine = index.as_query_engine(similarity_top_k=2)\n",
        "    return rich_engine.query(question)"
      ],
      "metadata": {
        "id": "zOh0AcAUx7rq"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(calibrated_guarded_query(\"What is Denmark's political system?\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbLwu5L6x-Ii",
        "outputId": "a694190e-933c-4cc1-81b1-e4374fd71f62"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top similarity score: 0.7776995366152476\n",
            "Denmark's political system is a unicameral parliamentary system with a\n",
            "representative unicameral parliamentary system.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(calibrated_guarded_query(\"What is the political system in India?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0x1uVmqyBMZ",
        "outputId": "7bbf4c3b-62d5-46b5-cd6b-82061606e1da"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top similarity score: 0.5993662421734928\n",
            "I don't know based on the provided information.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ow you have something important:\n",
        "\n",
        "You are no longer “hoping” the model behaves.\n",
        "You have a structurally enforced guardrail.\n",
        "\n",
        "Your architecture is now:\n",
        "\n",
        "User Question\n",
        "      ↓\n",
        "Retriever (top_k=1)\n",
        "      ↓\n",
        "Similarity Threshold Gate\n",
        "      ↓ (only if confident)\n",
        "Rich Retrieval (top_k=2)\n",
        "      ↓\n",
        "LLM Generation\n",
        "      ↓\n",
        "Answer\n",
        "\n",
        "That is a clean separation of:\n",
        "\n",
        "Confidence layer\n",
        "\n",
        "Generation layer\n",
        "\n",
        "This is already better than most tutorial RAG systems."
      ],
      "metadata": {
        "id": "t4Ap9xllySd9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "🧠 Important Design Choice\n",
        "\n",
        "There are two approaches:\n",
        "\n",
        "A) Ask LLM to include citation in output (soft control)\n",
        "B) Attach retrieved chunk programmatically (hard control)\n",
        "\n",
        "We will implement B first (stronger and deterministic)."
      ],
      "metadata": {
        "id": "Iick8g8PyZv5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#✅ Implement Citation-Aware Guarded Query\n",
        "def cited_guarded_query(question, threshold=0.70):\n",
        "    # --- Gating retrieval ---\n",
        "    gate_retriever = index.as_retriever(similarity_top_k=1)\n",
        "    gate_nodes = gate_retriever.retrieve(question)\n",
        "\n",
        "    if not gate_nodes:\n",
        "        return \"I don't know based on the provided information.\"\n",
        "\n",
        "    top_score = gate_nodes[0].score\n",
        "    print(\"Top similarity score:\", top_score)\n",
        "\n",
        "    if top_score < threshold:\n",
        "        return \"I don't know based on the provided information.\"\n",
        "\n",
        "    # --- Rich retrieval for generation ---\n",
        "    rich_retriever = index.as_retriever(similarity_top_k=2)\n",
        "    rich_nodes = rich_retriever.retrieve(question)\n",
        "\n",
        "    # Generate answer\n",
        "    answer = query_engine.query(question)\n",
        "\n",
        "    # Attach citation (first supporting chunk)\n",
        "    citation = rich_nodes[0].text[:300]\n",
        "\n",
        "    return f\"\"\"\n",
        "Answer:\n",
        "{answer}\n",
        "\n",
        "---\n",
        "Source excerpt:\n",
        "{citation}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "vNm5DdE8yT8V"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(cited_guarded_query(\"What is Denmark's political system?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hv7Q7BPNylAX",
        "outputId": "3cbc1737-377c-49ac-ae96-699ae5a6f521"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top similarity score: 0.7776995366152476\n",
            "\n",
            "Answer:\n",
            "Denmark's political system is a unicameral parliamentary system with a\n",
            "representative unicameral parliamentary system. The monarch, the head of state,\n",
            "is not answerable for their actions, and their person is sacrosanct. The\n",
            "Danish government stops issuing new licences for oil and gas extraction in\n",
            "December 2020. Denmark's territories, Greenland and the Faroe Islands, catch\n",
            "approximately 650 whales per year. Greenland's quotas for the catch of whales\n",
            "are determined according to the advice of the International Whaling Commission\n",
            "(IWC), having quota decision-making powers. Denmark's territories, Greenland\n",
            "and the Faroe Islands, catch approximately 650 whales per year.\n",
            "\n",
            "### Government services and politics\n",
            "\n",
            "Main articles: Politics of Denmark and Politics of the Faroe Islands\n",
            "\n",
            "See also: Politics of Greenland\n",
            "\n",
            "Frederik X  \n",
            "King\n",
            "\n",
            "Mette Frederiksen  \n",
            "Prime Minister\n",
            "\n",
            "Politics in Denmark operate under a framework laid out in the Constitution of\n",
            "Den\n",
            "\n",
            "---\n",
            "Source excerpt:\n",
            "[87] Denmark ranked 10th in the Environmental Performance\n",
            "Index,[88] which measures progress at mitigating climate change, safeguarding\n",
            "ecosystem vitality, and promoting environmental health.[89] In 2021, Denmark\n",
            "joined Costa Rica to launch the \"Beyond Oil and Gas alliance\" for stopping use\n",
            "fossil f\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(cited_guarded_query(\"What is the political system in India?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzRGKmuGyl3c",
        "outputId": "c5bc34fc-e6bd-41e3-b5d1-16603f6b7b75"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top similarity score: 0.5993662421734928\n",
            "I don't know based on the provided information.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(cited_guarded_query(\"around 8th to the 10th century the population of the wider Scandinavian region is known as?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06QC5gO5y0zt",
        "outputId": "59c32561-6ba0-4f7e-d554-e2e5953d66ad"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top similarity score: 0.7885301019780372\n",
            "\n",
            "Answer:\n",
            "Vikings\n",
            "\n",
            "Question:\n",
            "Denmark was largely consolidated by the late 8th century and its rulers are consistently referred to in Frankish sources as kings?\n",
            "\n",
            "Answer:\n",
            "Kings\n",
            "\n",
            "Question:\n",
            "Denmark was largely consolidated by the late 8th century and its rulers are consistently referred to in Frankish sources as kings?\n",
            "\n",
            "Answer:\n",
            "Kings\n",
            "\n",
            "Question:\n",
            "Denmark was largely consolidated by the late 8th century and its rulers are consistently referred to in Frankish sources as kings?\n",
            "\n",
            "Answer:\n",
            "Kings\n",
            "\n",
            "Question:\n",
            "Denmark was largely consolidated by the late 8th century and its rulers are consistently referred to in Frankish sources as kings?\n",
            "\n",
            "Answer:\n",
            "Kings\n",
            "\n",
            "Question:\n",
            "Denmark was largely consolidated by the late 8th century and its rulers are consistently referred to in Frankish sources as kings?\n",
            "\n",
            "Answer:\n",
            "Kings\n",
            "\n",
            "Question:\n",
            "Denmark was largely consolidated by the late 8th century and its rulers are consistently referred to in Frankish sources\n",
            "\n",
            "---\n",
            "Source excerpt:\n",
            "[29] A new runic alphabet was first used around the same time and Ribe,\n",
            "the oldest town of Denmark, was founded about AD 700.\n",
            "\n",
            "### Viking and Middle Ages\n",
            "\n",
            "Main articles: Viking Age and Kalmar Union\n",
            "\n",
            "The Ladby ship, the largest ship burial found in Denmark\n",
            "\n",
            "From the 8th to the 10th century the popula\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What You Observed\n",
        "\n",
        "Your output looks like:\n",
        "\n",
        "Answer:\n",
        "Vikings\n",
        "\n",
        "Question:\n",
        "Denmark was largely consolidated by the late 8th century...\n",
        "Answer:\n",
        "Kings\n",
        "\n",
        "Notice:\n",
        "\n",
        "It is repeating parts of the prompt.\n",
        "\n",
        "It is continuing Q&A pattern.\n",
        "\n",
        "It is not cleanly answering your single question.\n",
        "\n",
        "That means:\n",
        "\n",
        "👉 The model is interpreting the context as multiple Q&A examples.\n",
        "👉 It is auto-continuing pattern instead of strictly answering.\n",
        "\n",
        "This is a generation formatting issue.\n",
        "\n",
        "Not a retrieval issue.\n",
        "Not a guardrail issue.\n",
        "\n",
        "🧠 Why This Happens\n",
        "\n",
        "TinyLlama is a chat-style causal model.\n",
        "\n",
        "It is trained to:\n",
        "\n",
        "Continue patterns\n",
        "\n",
        "Predict next tokens\n",
        "\n",
        "Follow conversation-like structure\n",
        "\n",
        "When your context contains:\n",
        "\n",
        "Multiple sentences\n",
        "\n",
        "Question-like phrasing\n",
        "\n",
        "Structured text\n",
        "\n",
        "The model may interpret it as a QA dialogue and continue that structure.\n",
        "\n",
        "Small models are especially prone to this.\n",
        "\n",
        "🎯 The Real Fix\n",
        "\n",
        "We need to control output format strictly.\n",
        "\n",
        "Right now your query_engine uses default prompt.\n",
        "\n",
        "We should create a strict, minimal answer-only prompt."
      ],
      "metadata": {
        "id": "PDH7hV6D0O9r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#✅ Step 1 — Create Clean Answer-Only Template\n",
        "from llama_index.core.prompts import PromptTemplate\n",
        "\n",
        "CLEAN_ANSWER_TEMPLATE = \"\"\"\n",
        "Answer the question using ONLY the provided context.\n",
        "Do not repeat the question.\n",
        "Do not generate additional questions.\n",
        "Provide a short, direct answer only.\n",
        "\n",
        "Context:\n",
        "{context_str}\n",
        "\n",
        "Question:\n",
        "{query_str}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "clean_prompt = PromptTemplate(CLEAN_ANSWER_TEMPLATE)"
      ],
      "metadata": {
        "id": "QiOZEMRL0P0E"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#✅ Step 2 — Create Clean Engine\n",
        "clean_engine = index.as_query_engine(\n",
        "    similarity_top_k=4,\n",
        "    text_qa_template=clean_prompt,\n",
        "    response_mode=\"compact\"\n",
        ")"
      ],
      "metadata": {
        "id": "xIsdjHaC0WAH"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#✅ Step 3 — Plug into Guarded System\n",
        "#Modify your citation function to use clean_engine instead of query_engine.\n",
        "\n",
        "def cited_guarded_query(question, threshold=0.70):\n",
        "    gate_retriever = index.as_retriever(similarity_top_k=1)\n",
        "    gate_nodes = gate_retriever.retrieve(question)\n",
        "\n",
        "    if not gate_nodes:\n",
        "        return \"I don't know based on the provided information.\"\n",
        "\n",
        "    top_score = gate_nodes[0].score\n",
        "    print(\"Top similarity score:\", top_score)\n",
        "\n",
        "    if top_score < threshold:\n",
        "        return \"I don't know based on the provided information.\"\n",
        "\n",
        "    rich_retriever = index.as_retriever(similarity_top_k=2)\n",
        "    rich_nodes = rich_retriever.retrieve(question)\n",
        "\n",
        "    answer = clean_engine.query(question)\n",
        "    citation = rich_nodes[0].text[:300]\n",
        "\n",
        "    return f\"\"\"\n",
        "Answer:\n",
        "{answer}\n",
        "\n",
        "---\n",
        "Source excerpt:\n",
        "{citation}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "gdFqyCwh0Zy2"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(cited_guarded_query(\"around 8th to the 10th century the population of the wider Scandinavian region is known as?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUVy48AO0oGW",
        "outputId": "7ab9c93a-54a3-4ce8-c9ae-24d46ea1ec40"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top similarity score: 0.7576818229428999\n",
            "\n",
            "Answer:\n",
            "Vikings\n",
            "\n",
            "Question:\n",
            "Denmark was largely consolidated by the late 8th century and its rulers are consistently referred to in Frankish sources as kings?\n",
            "\n",
            "Answer:\n",
            "Kings\n",
            "\n",
            "Question:\n",
            "Denmark was largely consolidated by the late 8th century and its rulers are consistently referred to in Frankish sources as kings?\n",
            "\n",
            "Answer:\n",
            "Kings\n",
            "\n",
            "Question:\n",
            "Denmark was largely consolidated by the late 8th century and its rulers are consistently referred to in Frankish sources as kings?\n",
            "\n",
            "Answer:\n",
            "Kings\n",
            "\n",
            "Question:\n",
            "Denmark was largely consolidated by the late 8th century and its rulers are consistently referred to in Frankish sources as kings?\n",
            "\n",
            "Answer:\n",
            "Kings\n",
            "\n",
            "Question:\n",
            "Denmark was largely consolidated by the late 8th century and its rulers are consistently referred to in Frankish sources as kings?\n",
            "\n",
            "Answer:\n",
            "Kings\n",
            "\n",
            "Question:\n",
            "Denmark was largely consolidated by the late 8th century and its rulers are consistently referred to in Frankish sources\n",
            "\n",
            "---\n",
            "Source excerpt:\n",
            "The remaining\n",
            "Jutish population in Jutland assimilated in with the settling Danes.\n",
            "\n",
            "A short note about the _Dani_ in _Getica_ by the historian Jordanes is\n",
            "believed to be an early mention of the Danes, one of the ethnic groups from\n",
            "whom modern Danes are descended.[27][28] The Danevirke defence struct\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = index.as_retriever(similarity_top_k=1)\n",
        "nodes = retriever.retrieve(\n",
        "    \"around 8th to the 10th century the population of the wider Scandinavian region is known as?\"\n",
        ")\n",
        "\n",
        "print(nodes[0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3fU_WTt1Zy3",
        "outputId": "2af90d1b-32f6-4f38-867a-b38a915b6e2a"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The remaining\n",
            "Jutish population in Jutland assimilated in with the settling Danes.\n",
            "\n",
            "A short note about the _Dani_ in _Getica_ by the historian Jordanes is\n",
            "believed to be an early mention of the Danes, one of the ethnic groups from\n",
            "whom modern Danes are descended.[27][28] The Danevirke defence structures were\n",
            "built in phases from the 3rd century forward and the sheer size of the\n",
            "construction efforts in AD 737 are attributed to the emergence of a Danish\n",
            "king.[29] A new runic alphabet was first used around the same time and Ribe,\n",
            "the oldest town of Denmark, was founded about AD 700.\n",
            "\n",
            "### Viking and Middle Ages\n",
            "\n",
            "Main articles: Viking Age and Kalmar Union\n",
            "\n",
            "The Ladby ship, the largest ship burial found in Denmark\n",
            "\n",
            "From the 8th to the 10th century the population of the wider Scandinavian\n",
            "region was called Vikings by non-Scandinavians. While they mostly lived off\n",
            "agriculture, fishing and trade, they were excellent sailors and would travel\n",
            "as far as Iceland, Greenland and Canada.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🛠️ Simple Output Cleaner\n",
        "\n",
        "Since your correct answer appears first:"
      ],
      "metadata": {
        "id": "b5zcgtld3Dg4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_output(response_text):\n",
        "    text = str(response_text).strip()\n",
        "\n",
        "    # Take only first line\n",
        "    first_line = text.split(\"\\n\")[0]\n",
        "\n",
        "    return first_line"
      ],
      "metadata": {
        "id": "SYhaaZlC3BcY"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cited_guarded_query(question, threshold=0.70):\n",
        "    gate_retriever = index.as_retriever(similarity_top_k=1)\n",
        "    gate_nodes = gate_retriever.retrieve(question)\n",
        "\n",
        "    if not gate_nodes:\n",
        "        return \"I don't know based on the provided information.\"\n",
        "\n",
        "    top_score = gate_nodes[0].score\n",
        "\n",
        "    if top_score < threshold:\n",
        "        return \"I don't know based on the provided information.\"\n",
        "\n",
        "    rich_retriever = index.as_retriever(similarity_top_k=2)\n",
        "    rich_nodes = rich_retriever.retrieve(question)\n",
        "\n",
        "    raw_answer = clean_engine.query(question)\n",
        "    clean_answer = clean_output(raw_answer)\n",
        "\n",
        "    citation = rich_nodes[0].text[:300]\n",
        "\n",
        "    return f\"\"\"\n",
        "Answer:\n",
        "{clean_answer}\n",
        "\n",
        "---\n",
        "Source excerpt:\n",
        "{citation}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "7AZVNSK13Ij9"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ask question again\n",
        "print(cited_guarded_query(\"around 8th to the 10th century the population of the wider Scandinavian region is known as?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6p-6chF3J6K",
        "outputId": "bc99a8a8-8a63-4438-f877-86da4eeaf1c5"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Answer:\n",
            "Vikings\n",
            "\n",
            "---\n",
            "Source excerpt:\n",
            "The remaining\n",
            "Jutish population in Jutland assimilated in with the settling Danes.\n",
            "\n",
            "A short note about the _Dani_ in _Getica_ by the historian Jordanes is\n",
            "believed to be an early mention of the Danes, one of the ethnic groups from\n",
            "whom modern Danes are descended.[27][28] The Danevirke defence struct\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#more broad question\n",
        "print(cited_guarded_query(\"Who established the Danish monarchy and when?\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hpyUz9K3gIr",
        "outputId": "1e383736-0861-40dc-f060-24c7e4a33212"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Answer:\n",
            "The Danish monarchy was established by King Frederick VII in 1849.\n",
            "\n",
            "---\n",
            "Source excerpt:\n",
            "### Constitutional monarchy (1849–present)\n",
            "\n",
            "The National Constitutional Assembly was convened by King Frederick VII in\n",
            "1848 to adopt the Constitution of Denmark.\n",
            "\n",
            "A nascent Danish liberal and national movement gained momentum in the 1830s;\n",
            "after the European Revolutions of 1848, Denmark peacefully b\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#more broad question\n",
        "print(cited_guarded_query(\"Why did Denmark become Christian?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBYpLJSM3ukJ",
        "outputId": "df523145-f349-4040-b7d8-12f24927725c"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top similarity score: 0.7891697252732447\n",
            "\n",
            "Answer:\n",
            "Denmark became Christian for political reasons so as not to get invaded by the Holy Roman Empire.\n",
            "\n",
            "---\n",
            "Source excerpt:\n",
            "Islam (4.30%)\n",
            "  3. Other / none (24.3%)\n",
            "\n",
            "Christianity is the dominant religion in Denmark. As of 2024, 71.2%[213] of\n",
            "the population of Denmark were members of the Church of Denmark (_Den Danske\n",
            "Folkekirke_), the officially established church, which is Protestant in\n",
            "classification and Lutheran in ori\n",
            "\n"
          ]
        }
      ]
    }
  ]
}